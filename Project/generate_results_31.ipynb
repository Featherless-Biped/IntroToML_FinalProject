{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb74dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os, joblib\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from generate_features import generate_features\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "# from xgboost import XGBClassifier, plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "362fca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Also ensure the log CSV exists\n",
    "log_file = \"logs/model_log.csv\"\n",
    "if not os.path.exists(log_file):\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"model_id,model_type,AUC,date,params,notes\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85730f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reach\\AppData\\Local\\Temp\\ipykernel_14996\\2048193807.py:1: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(\"train.csv\")\n",
      "C:\\Users\\reach\\AppData\\Local\\Temp\\ipykernel_14996\\2048193807.py:2: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv(\"test.csv\")\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X, y, test = generate_features(train, test)\n",
    "\n",
    "# # ⚠️ TEMP: Subsample for debugging speed\n",
    "# X = X[:20000]\n",
    "# y = y[:20000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3cf06f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_v1():\n",
    "    model_id = \"knn_v1\"\n",
    "    model_type = \"KNN\"\n",
    "    notes = \"Baseline KNN: n_neighbors=5, weights=uniform\"\n",
    "\n",
    "    params = {\n",
    "        \"n_neighbors\": 5,\n",
    "        \"weights\": \"uniform\",\n",
    "        \"metric\": \"minkowski\",\n",
    "        \"p\": 2\n",
    "    }\n",
    "\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    print(f\"Top configuration: n_neighbors={params['n_neighbors']} | AUC: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2db5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_v2():\n",
    "    model_id = \"knn_v2\"\n",
    "    model_type = \"KNN\"\n",
    "    notes = \"Improved KNN: n_neighbors=7, weights=distance\"\n",
    "\n",
    "    params = {\n",
    "        \"n_neighbors\": 7,\n",
    "        \"weights\": \"distance\",\n",
    "        \"metric\": \"minkowski\",\n",
    "        \"p\": 2\n",
    "    }\n",
    "\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    print(f\"Top configuration: n_neighbors={params['n_neighbors']} | AUC: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cafe253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg_v1():\n",
    "    model_id = \"logreg_v1\"\n",
    "    model_type = \"LogisticRegression\"\n",
    "    notes = \"Standard Logistic Regression: l2, C=1.0\"\n",
    "\n",
    "    params = {\n",
    "        \"penalty\": \"l2\",\n",
    "        \"C\": 1.0,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 300,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed319f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg_v2():\n",
    "    model_id = \"logreg_v2\"\n",
    "    model_type = \"LogisticRegression\"\n",
    "    notes = \"Stronger regularization: l2, C=0.01\"\n",
    "\n",
    "    params = {\n",
    "        \"penalty\": \"l2\",\n",
    "        \"C\": 0.01,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 500,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f17bb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg_v3():\n",
    "    model_id = \"logreg_v3\"\n",
    "    model_type = \"LogisticRegression\"\n",
    "    notes = \"Sparse-friendly: l1, C=1.0, solver=liblinear\"\n",
    "\n",
    "    params = {\n",
    "        \"penalty\": \"l1\",\n",
    "        \"C\": 1.0,\n",
    "        \"solver\": \"liblinear\",\n",
    "        \"max_iter\": 500,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = LogisticRegression(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0367dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_rf_SPS1():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    model_id = \"rf_SPS1\"\n",
    "    model_type = \"RandomForest\"\n",
    "    notes = \"User baseline: 100 trees, depth=15, leaf=5\"\n",
    "\n",
    "    params = {\n",
    "    \"n_estimators\": 150,\n",
    "    \"max_depth\": 13,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    # Save results\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    if os.path.exists(log_path):\n",
    "        log = pd.read_csv(log_path)\n",
    "        log = pd.concat([log, entry], ignore_index=True)\n",
    "    else:\n",
    "        log = entry\n",
    "    log.to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_rf_SPS2():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    model_id = \"rf_SPS2\"\n",
    "    model_type = \"RandomForest\"\n",
    "    notes = \"User baseline: 100 trees, depth=15, leaf=5\"\n",
    "\n",
    "    base = DecisionTreeClassifier(max_depth=2)\n",
    "    params = { \n",
    "        \"n_estimators\": 300,\n",
    "    \"max_depth\": 17,\n",
    "    \"min_samples_leaf\": 2,   # <-- this is the key change\n",
    "    \"max_features\": \"log2\",  # slightly more selective\n",
    "    \"bootstrap\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    # Save results\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    if os.path.exists(log_path):\n",
    "        log = pd.read_csv(log_path)\n",
    "        log = pd.concat([log, entry], ignore_index=True)\n",
    "    else:\n",
    "        log = entry\n",
    "    log.to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0247719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_rf_v1():\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    model_id = \"rf_v1\"\n",
    "    model_type = \"RandomForest\"\n",
    "    notes = \"User baseline: 100 trees, depth=15, leaf=5\"\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 15,\n",
    "        \"min_samples_leaf\": 5,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"bootstrap\": True,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    # Save results\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    if os.path.exists(log_path):\n",
    "        log = pd.read_csv(log_path)\n",
    "        log = pd.concat([log, entry], ignore_index=True)\n",
    "    else:\n",
    "        log = entry\n",
    "    log.to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f28b181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_rf_v2():\n",
    "    model_id = \"rf_v2\"\n",
    "    model_type = \"RandomForest\"\n",
    "    notes = \"Suggested: 300 trees, depth=17, leaf=3 (more expressive)\"\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 19,\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"bootstrap\": True,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    # Plot feature importance\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-10:][::-1]\n",
    "    plt.bar(range(10), importances[indices])\n",
    "    plt.xticks(range(10), [str(i) for i in indices], rotation=45)\n",
    "    plt.title(\"Top 10 Feature Importances (RF v2)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b572716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adaboost_v1():\n",
    "    model_id = \"adaboost_v1\"\n",
    "    model_type = \"AdaBoost\"\n",
    "    notes = \"AdaBoost v1: n_estimators=300, learning_rate=0.5\"\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"learning_rate\": 0.2,\n",
    "        \"algorithm\":\"SAMME\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    base = DecisionTreeClassifier(max_depth=2)\n",
    "    model = AdaBoostClassifier(estimator=base, **params)    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61e6a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_v1():\n",
    "    model_id = \"svm_v1\"\n",
    "    model_type = \"SVM\"\n",
    "    notes = \"SVM with RBF kernel, C=1.0, gamma='scale', trained on 20k sample\"\n",
    "\n",
    "    params = {\n",
    "        \"C\": 1.0,\n",
    "        \"gamma\": \"scale\",\n",
    "        \"kernel\": \"linear\",\n",
    "        \"probability\": False,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    X_small, y_small = resample(X, y, n_samples=5000, stratify=y, random_state=42)\n",
    "    y_small = y_small.to_numpy()\n",
    "\n",
    "    model = SVC(kernel=\"linear\", C=1.0, probability=False)\n",
    "    # model = SVC(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_small, y_small):\n",
    "        model.fit(X_small[train_idx], y_small[train_idx])\n",
    "        val_scores = model.decision_function(X_small[val_idx])\n",
    "        auc = roc_auc_score(y_small[val_idx], val_scores)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.decision_function(test) / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba8a6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_v2():\n",
    "    model_id = \"svm_v2\"\n",
    "    model_type = \"SVM\"\n",
    "    notes = \"SVM with C=10.0, gamma='auto', trained on 20k sample, with overfit check\"\n",
    "\n",
    "    params = {\n",
    "        \"C\": 10.0,\n",
    "        \"gamma\": \"auto\",\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"probability\": False,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    X_small, y_small = resample(X, y, n_samples=5000, stratify=y, random_state=42)\n",
    "    y_small = y_small.to_numpy()\n",
    "\n",
    "    model = SVC(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_small, y_small):\n",
    "        model.fit(X_small[train_idx], y_small[train_idx])\n",
    "        train_scores = model.decision_function(X_small[train_idx])\n",
    "        val_scores = model.decision_function(X_small[val_idx])\n",
    "        train_auc = roc_auc_score(y_small[train_idx], train_scores)\n",
    "        val_auc = roc_auc_score(y_small[val_idx], val_scores)\n",
    "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "        aucs.append(val_auc)\n",
    "        test_preds += model.decision_function(test) / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b60ffb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb_v1():\n",
    "    model_id = \"xgb_v1\"\n",
    "    model_type = \"XGBoost\"\n",
    "    notes = \"Basic XGBoost model: depth=6, estimators=300, learning_rate=0.1\"\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plot_importance(model, max_num_features=10)\n",
    "    plt.title(\"Top 10 Feature Importances (XGB v1)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46661935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_xgb_v2():\n",
    "    model_id = \"xgb_v2\"\n",
    "    model_type = \"XGBoost\"\n",
    "    notes = \"Shallower trees: depth=3, estimators=100 to check overfitting\"\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        train_probs = model.predict_proba(X[train_idx])[:, 1]\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        print(f\"Train AUC: {roc_auc_score(y[train_idx], train_probs):.4f} | Val AUC: {roc_auc_score(y[val_idx], val_probs):.4f}\")\n",
    "        aucs.append(roc_auc_score(y[val_idx], val_probs))\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"✅ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plot_importance(model, max_num_features=10)\n",
    "    plt.title(\"Top 10 Feature Importances (XGB v2)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AUC (rf_v1): 0.9225302030502907\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# run_knn_v1()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# run_knn_v2()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# run_rf_SPS1()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m run_rf_SPS2()\n\u001b[1;32m---> 12\u001b[0m run_adaboost_v1()\n",
      "Cell \u001b[1;32mIn[65], line 20\u001b[0m, in \u001b[0;36mrun_adaboost_v1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m aucs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_idx, val_idx \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(X, y):\n\u001b[1;32m---> 20\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X[train_idx], y[train_idx])\n\u001b[0;32m     21\u001b[0m     val_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X[val_idx])[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     22\u001b[0m     auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y[val_idx], val_probs)\n",
      "File \u001b[1;32mc:\\Users\\reach\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\reach\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:169\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    166\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost(\n\u001b[0;32m    170\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[0;32m    171\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\reach\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:597\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32mc:\\Users\\reach\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:664\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_discrete\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME discrete algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    662\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 664\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    666\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\reach\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\reach\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1010\u001b[0m         X,\n\u001b[0;32m   1011\u001b[0m         y,\n\u001b[0;32m   1012\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1013\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reach\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the models\n",
    "# run_knn_v1()\n",
    "# run_knn_v2()\n",
    "# run_logreg_v1()\n",
    "# run_logreg_v2()\n",
    "# run_logreg_v3()\n",
    "run_rf_v1()\n",
    "run_rf_v2()\n",
    "run_rf_SPS1()\n",
    "run_rf_SPS2()\n",
    "\n",
    "run_adaboost_v1()\n",
    "# run_xgb_v1()\n",
    "# run_xgb_v2()\n",
    "\n",
    "# run_svm_v1()\n",
    "# run_svm_v2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
