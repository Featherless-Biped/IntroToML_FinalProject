{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier, plot_importance as lgbm_plot_importance, early_stopping, log_evaluation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "from generate_features import generate_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Also ensure the log CSV exists\n",
    "log_file = \"logs/model_log.csv\"\n",
    "if not os.path.exists(log_file):\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"model_id,model_type,AUC,date,params,notes\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85730f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X, y, test, feature_names = generate_features(train, test, return_feature_names=True)\n",
    "X_small, y_small = resample(X, y, n_samples=20000, stratify=y, random_state=42)\n",
    "\n",
    "# # ‚ö†Ô∏è TEMP: Subsample for debugging speed\n",
    "# X = X[:20000]\n",
    "# y = y[:20000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3786185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_model(model_id, params, notes):\n",
    "    model_type = \"KNN\"\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"‚úÖ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    entry = pd.DataFrame([{ \"model_id\": model_id, \"model_type\": model_type, \"AUC\": mean_auc, \"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"params\": str(params), \"notes\": notes }])\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg_model(model_id, params, notes, feature_names=None):\n",
    "    model_type = \"LogReg\"\n",
    "    model = LogisticRegression(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"‚úÖ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    entry = pd.DataFrame([{ \"model_id\": model_id, \"model_type\": model_type, \"AUC\": mean_auc, \"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"params\": str(params), \"notes\": notes }])\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    if feature_names is not None and hasattr(model, 'coef_'):\n",
    "        importances = np.abs(model.coef_[0])\n",
    "        indices = np.argsort(importances)[-10:][::-1]\n",
    "        plt.barh([feature_names[i] for i in indices], importances[indices])\n",
    "        plt.xlabel(\"Feature importance (abs coef)\")\n",
    "        plt.title(f\"Top 10 Feature Importances ({model_id})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798572e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_model(model_id, params, notes):\n",
    "    model_type = \"SVM\"\n",
    "    model = SVC(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    X_small, y_small = resample(X, y, n_samples=5000, stratify=y, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_small, y_small):\n",
    "        model.fit(X_small[train_idx], y_small[train_idx])\n",
    "        val_scores = model.decision_function(X_small[val_idx])\n",
    "        auc = roc_auc_score(y_small[val_idx], val_scores)\n",
    "        aucs.append(auc)\n",
    "        test_preds += model.decision_function(test) / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"‚úÖ AUC ({model_id}):\", mean_auc)\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    entry = pd.DataFrame([{ \"model_id\": model_id, \"model_type\": model_type, \"AUC\": mean_auc, \"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"params\": str(params), \"notes\": notes }])\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efbe1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adaboost_model(model_id, params, notes, feature_names):\n",
    "    model_type = \"AdaBoost\"\n",
    "    base = DecisionTreeClassifier(max_depth=2)\n",
    "    model = AdaBoostClassifier(estimator=base, **params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nüü¢ Fold {fold + 1}\")\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        train_probs = model.predict_proba(X[train_idx])[:, 1]\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        train_auc = roc_auc_score(y[train_idx], train_probs)\n",
    "        val_auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "        aucs.append(val_auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"\\n‚úÖ AUC ({model_id}): {mean_auc:.6f}\")\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{ \"model_id\": model_id, \"model_type\": model_type, \"AUC\": mean_auc, \"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"params\": str(params), \"notes\": notes }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-10:][::-1]\n",
    "    plt.barh([feature_names[i] for i in indices], importances[indices])\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.title(f\"Top 10 Feature Importances ({model_id})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb_model(model_id, params, notes, X, y, test, feature_names):\n",
    "    from xgboost import XGBClassifier, plot_importance\n",
    "    model_type = \"XGBoost\"\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "    models = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nüü¢ Fold {fold + 1}\")\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        model = XGBClassifier(**params, n_estimators=10000)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            early_stopping_rounds=30,\n",
    "            verbose=100\n",
    "        )\n",
    "\n",
    "        train_probs = model.predict_proba(X_train)[:, 1]\n",
    "        val_probs = model.predict_proba(X_val)[:, 1]\n",
    "        train_auc = roc_auc_score(y_train, train_probs)\n",
    "        val_auc = roc_auc_score(y_val, val_probs)\n",
    "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        aucs.append(val_auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "        models.append(model)\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"\\n‚úÖ AUC ({model_id}): {mean_auc:.6f}\")\n",
    "\n",
    "    joblib.dump(models[-1], f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{ \n",
    "        \"model_id\": model_id, \"model_type\": model_type, \"AUC\": mean_auc, \n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"params\": str(params), \"notes\": notes \n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    # Plot top 10 feature importances\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-10:][::-1]\n",
    "    plt.barh([feature_names[i] for i in indices], importances[indices])\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.title(f\"Top 10 Feature Importances ({model_id})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_catboost_model(model_id, params, notes, feature_names):\n",
    "    model_type = \"CatBoost\"\n",
    "    model = CatBoostClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nüü¢ Fold {fold + 1}\")\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        train_probs = model.predict_proba(X[train_idx])[:, 1]\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        train_auc = roc_auc_score(y[train_idx], train_probs)\n",
    "        val_auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "        aucs.append(val_auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"\\n‚úÖ AUC ({model_id}): {mean_auc:.6f}\")\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{ \"model_id\": model_id, \"model_type\": model_type, \"AUC\": mean_auc, \"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"params\": str(params), \"notes\": notes }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    importances = model.get_feature_importance()\n",
    "    indices = np.argsort(importances)[-10:][::-1]\n",
    "    plt.barh([feature_names[i] for i in indices], importances[indices])\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.title(f\"Top 10 Feature Importances ({model_id})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbm_model(model_id, params, notes, feature_names):\n",
    "\n",
    "    model_type = \"LightGBM\"\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "    models = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nüü¢ Fold {fold + 1}\")\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        model = LGBMClassifier(\n",
    "            **params,\n",
    "            n_estimators=1000\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[\n",
    "                early_stopping(stopping_rounds=30),\n",
    "                log_evaluation(period=100)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        train_probs = model.predict_proba(X_train)[:, 1]\n",
    "        val_probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        train_auc = roc_auc_score(y_train, train_probs)\n",
    "        val_auc = roc_auc_score(y_val, val_probs)\n",
    "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        aucs.append(val_auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "        models.append(model)\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"\\n‚úÖ AUC ({model_id}): {mean_auc:.6f}\")\n",
    "\n",
    "    joblib.dump(models[-1], f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"AUC\": mean_auc,\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"params\": str(params),\n",
    "        \"notes\": notes\n",
    "    }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    # Plot top 10 feature importances with real feature names\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:10]\n",
    "    top_names = [feature_names[i] for i in indices]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh(range(10), importances[indices][::-1])\n",
    "    plt.yticks(range(10), [top_names[i] for i in range(9, -1, -1)])\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.title(f\"Top 10 Feature Importances ({model_id})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0827ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_model(model_id, params, notes, feature_names):\n",
    "    model_type = \"RandomForest\"\n",
    "    model = RandomForestClassifier(**params)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    aucs = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nüü¢ Fold {fold + 1}\")\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        train_probs = model.predict_proba(X[train_idx])[:, 1]\n",
    "        val_probs = model.predict_proba(X[val_idx])[:, 1]\n",
    "        train_auc = roc_auc_score(y[train_idx], train_probs)\n",
    "        val_auc = roc_auc_score(y[val_idx], val_probs)\n",
    "        print(f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "        aucs.append(val_auc)\n",
    "        test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    mean_auc = np.mean(aucs)\n",
    "    print(f\"\\n‚úÖ AUC ({model_id}): {mean_auc:.6f}\")\n",
    "\n",
    "    joblib.dump(model, f\"models/{model_id}.pkl\")\n",
    "    pd.DataFrame({\"Id\": range(len(test_preds)), \"Prediction\": test_preds}).to_csv(f\"results/{model_id}.csv\", index=False)\n",
    "\n",
    "    log_path = \"logs/model_log.csv\"\n",
    "    entry = pd.DataFrame([{ \"model_id\": model_id, \"model_type\": model_type, \"AUC\": mean_auc, \"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"params\": str(params), \"notes\": notes }])\n",
    "    log = pd.read_csv(log_path) if os.path.exists(log_path) else pd.DataFrame()\n",
    "    pd.concat([log, entry], ignore_index=True).to_csv(log_path, index=False)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-10:][::-1]\n",
    "    plt.barh([feature_names[i] for i in indices], importances[indices])\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.title(f\"Top 10 Feature Importances ({model_id})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grids\n",
    "lgbm_param_grid = [\n",
    "    {\"num_leaves\": 60, \"max_depth\": 8, \"learning_rate\": 0.04, \"subsample\": 0.85, \"colsample_bytree\": 0.9, \"random_state\": 42},\n",
    "    {\"num_leaves\": 80, \"max_depth\": 10, \"learning_rate\": 0.03, \"subsample\": 0.9, \"colsample_bytree\": 0.85, \"random_state\": 42},\n",
    "    {\"num_leaves\": 100, \"max_depth\": 12, \"learning_rate\": 0.025, \"subsample\": 0.95, \"colsample_bytree\": 0.9, \"random_state\": 42},\n",
    "    {\"num_leaves\": 40, \"max_depth\": 6, \"learning_rate\": 0.02, \"subsample\": 0.85, \"colsample_bytree\": 0.95, \"random_state\": 42},\n",
    "    {\"num_leaves\": 30, \"max_depth\": 5, \"learning_rate\": 0.01, \"subsample\": 0.9, \"colsample_bytree\": 1.0, \"random_state\": 42}\n",
    "]\n",
    "\n",
    "catboost_param_grid = [\n",
    "    {\"iterations\": 500, \"depth\": 6, \"learning_rate\": 0.03, \"loss_function\": \"Logloss\", \"verbose\": 0, \"random_seed\": 42},\n",
    "    {\"iterations\": 600, \"depth\": 8, \"learning_rate\": 0.025, \"loss_function\": \"Logloss\", \"verbose\": 0, \"random_seed\": 42},\n",
    "    {\"iterations\": 700, \"depth\": 7, \"learning_rate\": 0.02, \"loss_function\": \"Logloss\", \"verbose\": 0, \"random_seed\": 42}\n",
    "]\n",
    "xgb_param_grid = [\n",
    "    {\"n_estimators\": 10000, \"max_depth\": 6, \"learning_rate\": 0.035, \"subsample\": 0.9, \"colsample_bytree\": 0.9, \"eval_metric\": \"logloss\", \"random_state\": 42, \"use_label_encoder\": False},\n",
    "    {\"n_estimators\": 10000, \"max_depth\": 5, \"learning_rate\": 0.03, \"subsample\": 0.85, \"colsample_bytree\": 0.8, \"eval_metric\": \"logloss\", \"random_state\": 42, \"use_label_encoder\": False},\n",
    "    {\"n_estimators\": 10000, \"max_depth\": 4, \"learning_rate\": 0.02, \"subsample\": 1.0, \"colsample_bytree\": 1.0, \"eval_metric\": \"logloss\", \"random_state\": 42, \"use_label_encoder\": False},\n",
    "    {\"n_estimators\": 10000, \"max_depth\": 5, \"learning_rate\": 0.015, \"subsample\": 0.9, \"colsample_bytree\": 0.85, \"eval_metric\": \"logloss\", \"random_state\": 42, \"use_label_encoder\": False},\n",
    "    {\"n_estimators\": 10000, \"max_depth\": 3, \"learning_rate\": 0.01, \"subsample\": 0.95, \"colsample_bytree\": 0.95, \"eval_metric\": \"logloss\", \"random_state\": 42, \"use_label_encoder\": False}\n",
    "]\n",
    "\n",
    "rf_param_grid = [\n",
    "    {\"n_estimators\": 300, \"max_depth\": 12, \"min_samples_leaf\": 2, \"max_features\": \"sqrt\", \"bootstrap\": True, \"random_state\": 42, \"n_jobs\": -1},\n",
    "    {\"n_estimators\": 400, \"max_depth\": 15, \"min_samples_leaf\": 2, \"max_features\": 0.8, \"bootstrap\": True, \"random_state\": 42, \"n_jobs\": -1}\n",
    "]\n",
    "adaboost_param_grid = [\n",
    "    {\"n_estimators\": 300, \"learning_rate\": 0.1, \"random_state\": 42},\n",
    "    {\"n_estimators\": 500, \"learning_rate\": 0.05, \"random_state\": 42}\n",
    "]\n",
    "logreg_param_grid = [\n",
    "    {\"solver\": \"liblinear\", \"C\": 1.0, \"max_iter\": 200},\n",
    "    {\"solver\": \"liblinear\", \"C\": 0.5, \"max_iter\": 200}\n",
    "]\n",
    "svm_param_grid = [\n",
    "    {\"C\": 1.0, \"kernel\": \"linear\", \"probability\": False, \"random_state\": 42},\n",
    "    {\"C\": 0.5, \"kernel\": \"linear\", \"probability\": False, \"random_state\": 42}\n",
    "]\n",
    "knn_param_grid = [\n",
    "    {\"n_neighbors\": 5},\n",
    "    {\"n_neighbors\": 7}\n",
    "]\n",
    "\n",
    "model_configs = [\n",
    "    # (\"lgbm\", run_lgbm_model, lgbm_param_grid, X, y, True),\n",
    "    (\"xgb\", run_xgb_model, xgb_param_grid, X, y, True),\n",
    "    (\"rf\", run_rf_model, rf_param_grid, X, y, True),\n",
    "    (\"catboost\", run_catboost_model, catboost_param_grid, X, y, False),\n",
    "    (\"adaboost\", run_adaboost_model, adaboost_param_grid, X, y, True),\n",
    "    (\"logreg\", run_logreg_model, logreg_param_grid, X, y, True),\n",
    "    (\"svm\", run_svm_model, svm_param_grid, X_small, y_small, False),\n",
    "    (\"knn\", run_knn_model, knn_param_grid, X_small, y_small, False)\n",
    "]\n",
    "\n",
    "# Run all model configs with all param sets\n",
    "for model_prefix, func, param_list, X_used, y_used, pass_features in model_configs:\n",
    "    for i, params in enumerate(param_list):\n",
    "        model_id = f\"{model_prefix}_v{i+1}\"\n",
    "        print(f\"\\nüöÄ Running {model_id}...\")\n",
    "\n",
    "        try:\n",
    "            if pass_features:\n",
    "                func(model_id, params, f\"{model_prefix.upper()} config #{i+1}\", feature_names)\n",
    "            else:\n",
    "                func(model_id, params, f\"{model_prefix.upper()} config #{i+1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR in {model_id}: {e}\")\n",
    "            continue  # Move to the next config\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
